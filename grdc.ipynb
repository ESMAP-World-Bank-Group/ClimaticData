{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T12:37:51.924343Z",
     "start_time": "2025-04-18T12:37:50.827856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "from utils import *\n",
    "\n",
    "import geopandas as gpd"
   ],
   "id": "3a43cbf66c979286",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-18T12:37:51.930436Z",
     "start_time": "2025-04-18T12:37:51.928337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "folder = 'GRDC/guinea'\n",
    "folder_out = 'GRDC/guinea/output'\n",
    "if not os.path.exists(folder_out): os.makedirs(folder_out)\n",
    "\n",
    "file_discharge = os.path.join(folder, 'GRDC-Monthly.nc')\n",
    "file_stationbasins = os.path.join(folder, 'stationbasins.geojson')\n",
    "file_subregions = os.path.join(folder, 'subregions.geojson')"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T12:37:52.639427Z",
     "start_time": "2025-04-18T12:37:52.027990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make a map of data location\n",
    "map_grdc_stationbasins_and_subregions(folder_out, file_stationbasins, file_subregions=None)"
   ],
   "id": "cdaf2409c553cc35",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/HydroData/lib/python3.10/site-packages/pyogrio/raw.py:198: RuntimeWarning: organizePolygons() received a polygon with more than 100 parts. The processing may be really slow.  You can skip the processing by setting METHOD=SKIP, or only make it analyze counter-clock wise parts by setting METHOD=ONLY_CCW if you can assume that the outline of holes is counter-clock wise defined\n",
      "  return ogr_read(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map saved to map_stations_and_subregions.html\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T12:37:53.178481Z",
     "start_time": "2025-04-18T12:37:52.651755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "data_location = gpd.read_file(file_stationbasins)\n",
    "data_discharge = xr.open_dataset(file_discharge)"
   ],
   "id": "8fbece508481ef9c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T12:37:53.236899Z",
     "start_time": "2025-04-18T12:37:53.193314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare export data\n",
    "var_name = 'runoff_mean'\n",
    "\n",
    "meta = data_discharge[[\"station_name\", \"geo_x\", \"geo_y\"]].to_dataframe().reset_index()\n",
    "area = data_discharge[\"area\"].to_dataframe().reset_index()\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = data_discharge[var_name].to_dataframe(name=\"Q\").reset_index()\n",
    "\n",
    "# Merge metadata into the main DataFrame\n",
    "df = df.merge(meta, on=\"id\")\n",
    "df = df.merge(area, on=\"id\")\n",
    "\n",
    "# Add year and month columns\n",
    "df[\"year\"] = df[\"time\"].dt.year\n",
    "df[\"month\"] = df[\"time\"].dt.month\n",
    "\n",
    "# Create a unique label for each station using name + coordinates (optional)\n",
    "df[\"station_label\"] = df[\"station_name\"].str.strip() + \" (\" + df[\"geo_y\"].round(2).astype(str) + \", \" + df[\"geo_x\"].round(2).astype(str) + \")\"\n",
    "\n",
    "# Pivot to wide format: year as index, MultiIndex (month, id) as columns\n",
    "df_pivot = df.pivot(index=\"year\", columns=[\"station_name\", \"month\"], values=\"Q\")\n",
    "df_pivot.dropna(axis=1, how='all', inplace=True)\n",
    "df_pivot.sort_index(ascending=True, axis=1, inplace=True)\n",
    "df_pivot.to_csv(os.path.join(folder_out, 'GRDC_discharge_monthly-m3-s.csv'), index=True)"
   ],
   "id": "f64c637dae24cb0a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T12:39:12.812253Z",
     "start_time": "2025-04-18T12:39:12.807276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def filter_full_years(df):\n",
    "    \"\"\"\n",
    "    Keep only (station, year) pairs with 12 valid months.\n",
    "    Returns filtered DataFrame and number of dropped rows.\n",
    "    \"\"\"\n",
    "    original_len = len(df)\n",
    "\n",
    "    # Count valid months per station-year\n",
    "    valid_counts = (\n",
    "        df.groupby(['station_name', 'year'])['Q']\n",
    "        .apply(lambda x: x.notna().sum())\n",
    "        .reset_index(name='valid_months')\n",
    "    )\n",
    "\n",
    "    # Only keep those with all 12 months\n",
    "    full_years = valid_counts[valid_counts['valid_months'] == 12]\n",
    "\n",
    "    # Merge to filter original DataFrame\n",
    "    df_filtered = df.merge(full_years[['station_name', 'year']], on=['station_name', 'year'])\n",
    "\n",
    "    removed_rows = original_len - len(df_filtered)\n",
    "    print(f\"Removed {removed_rows} rows — kept {len(df_filtered)} only full (12-month) years.\")\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "def discharge_to_runoff(df):\n",
    "    \"\"\"\n",
    "    Convert annual discharge (m³/s) into annual runoff (mm/year) at the station level.\n",
    "\n",
    "    The equation used is:\n",
    "\n",
    "        runoff_mm = (Σ(Q_monthly_avg × 86400 × days_in_month)) / area_m2 × 1000\n",
    "\n",
    "    Where:\n",
    "        - Q is discharge in m³/s\n",
    "        - 86400 is seconds per day\n",
    "        - days_in_month accounts for monthly totals\n",
    "        - area is the catchment area in m²\n",
    "        - 1000 converts meters to millimeters\n",
    "\n",
    "    Assumes:\n",
    "        - Input DataFrame has one row per station/month\n",
    "        - Years are complete (12 months per station)\n",
    "\n",
    "    Returns:\n",
    "        - DataFrame with columns: station_label, year, runoff_mm_year\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Add number of days in each month\n",
    "    df['days_in_month'] = pd.to_datetime(df['time']).dt.days_in_month\n",
    "\n",
    "    # Convert area to m²\n",
    "    df['area_m2'] = df['area'] * 1e6\n",
    "\n",
    "    # Compute volume in m³ for each month\n",
    "    df['volume_m3'] = df['Q'] * 86400 * df['days_in_month']\n",
    "\n",
    "    # Sum monthly volumes per station-year\n",
    "    runoff_by_year = (\n",
    "        df.groupby(['station_name', 'year'])\n",
    "        .apply(lambda x: x['volume_m3'].sum() / x['area_m2'].iloc[0] * 1000)  # m to mm\n",
    "        .reset_index(name='runoff_mm_year')\n",
    "    )\n",
    "\n",
    "    return runoff_by_year"
   ],
   "id": "df03fffed797054a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T12:39:13.326090Z",
     "start_time": "2025-04-18T12:39:13.207132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert discharge data (m3-s) to runoff in (mm-year)\n",
    "df_filtered = filter_full_years(df)\n",
    "runoff_by_year = discharge_to_runoff(df_filtered)\n",
    "# Save to CSV\n",
    "runoff_by_year.round(0).pivot(index=\"year\", columns=\"station_name\", values=\"runoff_mm_year\").to_csv(os.path.join(folder_out, 'GRDC_runoff_mm-year.csv'), index=True)"
   ],
   "id": "6b0b80b52d97ebea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 19332 rows — kept 3948 only full (12-month) years.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p9/3r4_fgzd72j7b469xxshgfnh0000gn/T/ipykernel_82814/3640971745.py:62: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x['volume_m3'].sum() / x['area_m2'].iloc[0] * 1000)  # m to mm\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T12:37:18.959526Z",
     "start_time": "2025-04-18T12:37:18.951210Z"
    }
   },
   "cell_type": "code",
   "source": "runoff_by_year",
   "id": "ebe6537e2671f7d7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                station_label  year  runoff_mm_year\n",
       "0           BAC (8.06, -9.07)  1977      590.579331\n",
       "1           BAC (8.06, -9.07)  1978      811.859021\n",
       "2           BAC (8.06, -9.07)  1979      754.159085\n",
       "3           BAC (8.06, -9.07)  1980      590.713597\n",
       "4           BAC (8.06, -9.07)  1995      679.963798\n",
       "..                        ...   ...             ...\n",
       "324  TINKISSO (11.25, -10.62)  1972      280.206021\n",
       "325  TINKISSO (11.25, -10.62)  1973      250.626850\n",
       "326  TINKISSO (11.25, -10.62)  1975      354.212934\n",
       "327  TINKISSO (11.25, -10.62)  1977      170.774893\n",
       "328  TINKISSO (11.25, -10.62)  1978      193.482860\n",
       "\n",
       "[329 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_label</th>\n",
       "      <th>year</th>\n",
       "      <th>runoff_mm_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BAC (8.06, -9.07)</td>\n",
       "      <td>1977</td>\n",
       "      <td>590.579331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAC (8.06, -9.07)</td>\n",
       "      <td>1978</td>\n",
       "      <td>811.859021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAC (8.06, -9.07)</td>\n",
       "      <td>1979</td>\n",
       "      <td>754.159085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BAC (8.06, -9.07)</td>\n",
       "      <td>1980</td>\n",
       "      <td>590.713597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BAC (8.06, -9.07)</td>\n",
       "      <td>1995</td>\n",
       "      <td>679.963798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>TINKISSO (11.25, -10.62)</td>\n",
       "      <td>1972</td>\n",
       "      <td>280.206021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>TINKISSO (11.25, -10.62)</td>\n",
       "      <td>1973</td>\n",
       "      <td>250.626850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>TINKISSO (11.25, -10.62)</td>\n",
       "      <td>1975</td>\n",
       "      <td>354.212934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>TINKISSO (11.25, -10.62)</td>\n",
       "      <td>1977</td>\n",
       "      <td>170.774893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>TINKISSO (11.25, -10.62)</td>\n",
       "      <td>1978</td>\n",
       "      <td>193.482860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T12:37:19.008612Z",
     "start_time": "2025-04-18T12:37:19.001221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fill_missing_climatology(df, min_months=3):\n",
    "    \"\"\"\n",
    "    Fill missing values using monthly climatology (station-wise).\n",
    "    Returns a filled DataFrame and a mask of filled values.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Step 1: Filter out sparse years\n",
    "    valid_years = (\n",
    "        df.groupby([\"station_label\", \"year\"])[\"Q\"]\n",
    "        .apply(lambda x: x.notna().sum() >= min_months)\n",
    "        .reset_index(name=\"keep\")\n",
    "    )\n",
    "\n",
    "    # Merge to filter out sparse rows\n",
    "    df = df.merge(valid_years[valid_years[\"keep\"]], on=[\"station_label\", \"year\"])\n",
    "    df.drop(columns=\"keep\", inplace=True)\n",
    "\n",
    "    # Step 2: Build climatology\n",
    "    climatology = (\n",
    "        df.groupby([\"station_label\", \"month\"])[\"Q\"]\n",
    "        .mean()\n",
    "        .rename(\"Q_clim\")\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    df = df.merge(climatology, on=[\"station_label\", \"month\"], how=\"left\")\n",
    "\n",
    "    # Step 3: Fill missing with climatology\n",
    "    fill_mask = df[\"Q\"].isna()\n",
    "    df.loc[fill_mask, \"Q\"] = df.loc[fill_mask, \"Q_clim\"]\n",
    "\n",
    "    df.drop(columns=\"Q_clim\", inplace=True)\n",
    "\n",
    "    return df_filled, filled_mask\n",
    "\n",
    "def drop_sparse_years_and_interpolate(df, min_months=9):\n",
    "    \"\"\"\n",
    "    Drops years with too much missing data and interpolates gaps per station.\n",
    "    Assumes monthly data. Returns cleaned & interpolated DataFrame.\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    # Count non-NaN entries per year-station\n",
    "    valid_counts = (\n",
    "        df_clean.groupby([\"station_label\", \"year\"])[\"Q\"]\n",
    "        .apply(lambda x: x.notna().sum())\n",
    "        .rename(\"valid_months\")\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Keep only rows with enough months\n",
    "    valid_years = valid_counts[valid_counts[\"valid_months\"] >= min_months]\n",
    "    df_clean = df_clean.merge(valid_years[[\"station_label\", \"year\"]], on=[\"station_label\", \"year\"])\n",
    "\n",
    "    # Sort for interpolation\n",
    "    df_clean = df_clean.sort_values([\"station_label\", \"year\", \"month\"])\n",
    "\n",
    "    # Interpolate per station\n",
    "    df_clean[\"Q\"] = df_clean.groupby(\"station_label\")[\"Q\"].transform(lambda x: x.interpolate(method='linear', limit_direction='both'))\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "def plot_all_fill_methods(df_original, df_clim, df_interp, output_dir):\n",
    "    \"\"\"\n",
    "    Plots original, climatology-filled, and interpolated runoff data per station in one plot.\n",
    "\n",
    "    Assumes all DataFrames have columns: ['year', 'month', 'station_label', 'Q'].\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_dir = os.path.join(output_dir, 'plots')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Combine 'year' and 'month' into datetime\n",
    "    def add_datetime(df):\n",
    "        return df.assign(\n",
    "            date=pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str).str.zfill(2))\n",
    "        )\n",
    "\n",
    "    df_original = add_datetime(df_original)\n",
    "    df_clim = add_datetime(df_clim)\n",
    "    df_interp = add_datetime(df_interp)\n",
    "\n",
    "    # Loop over each station\n",
    "    stations = df_original['station_label'].unique()\n",
    "\n",
    "    for station in stations:\n",
    "        fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "        # Subsets for current station\n",
    "        df_o = df_original[df_original['station_label'] == station]\n",
    "        df_c = df_clim[df_clim['station_label'] == station]\n",
    "        df_i = df_interp[df_interp['station_label'] == station]\n",
    "\n",
    "        # Plot all\n",
    "        ax.plot(df_o['date'], df_o['Q'], label=\"Original\", alpha=0.5, marker='o', linestyle='-', color='black')\n",
    "        ax.plot(df_c['date'], df_c['Q'], label=\"Climatology Fill\", linestyle='--', color='orange')\n",
    "        ax.plot(df_i['date'], df_i['Q'], label=\"Interpolated\", linestyle='-', color='blue')\n",
    "\n",
    "        ax.set_title(f\"Station: {station}\")\n",
    "        ax.set_ylabel(\"Discharge / Runoff (Q)\")\n",
    "        ax.set_xlabel(\"Time\")\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f\"{station}.png\"))\n",
    "        plt.close()\n"
   ],
   "id": "57011395a5bcb5b",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T12:37:19.156901Z",
     "start_time": "2025-04-18T12:37:19.030649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_filled, filled_mask = fill_missing_climatology(df, min_months=6)\n",
    "df_interpolated = drop_sparse_years_and_interpolate(df, min_months=9)\n",
    "plot_all_fill_methods(df, df_filled, df_interpolated, output_dir=folder)"
   ],
   "id": "52e919231d3dacdf",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_filled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[35], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m df_filled, filled_mask \u001B[38;5;241m=\u001B[39m \u001B[43mfill_missing_climatology\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmin_months\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m6\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m df_interpolated \u001B[38;5;241m=\u001B[39m drop_sparse_years_and_interpolate(df, min_months\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m9\u001B[39m)\n\u001B[1;32m      3\u001B[0m plot_all_fill_methods(df, df_filled, df_interpolated, output_dir\u001B[38;5;241m=\u001B[39mfolder)\n",
      "Cell \u001B[0;32mIn[34], line 35\u001B[0m, in \u001B[0;36mfill_missing_climatology\u001B[0;34m(df, min_months)\u001B[0m\n\u001B[1;32m     31\u001B[0m df\u001B[38;5;241m.\u001B[39mloc[fill_mask, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mQ\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mloc[fill_mask, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mQ_clim\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     33\u001B[0m df\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mQ_clim\u001B[39m\u001B[38;5;124m\"\u001B[39m, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 35\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdf_filled\u001B[49m, filled_mask\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df_filled' is not defined"
     ]
    }
   ],
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
